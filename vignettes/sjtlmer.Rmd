---
title: "Summary of Linear Mixed Regression Models as HTML Table"
author: "Daniel LÃ¼decke"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Summary of Linear Mixed Regression Models as HTML Table}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r echo = FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>", message = FALSE)
```

This document shows examples for using the `sjt.lmer()` function of the sjPlot package.

```{r, results='hide', message=FALSE, warning=FALSE}
# load required packages
library(sjPlot)
library(sjmisc)
library(lme4)
```

## Linear mixed models summaries as HTML table

The `sjt.lmer()` function prints summaries of linear mixed models (fitted with the `lmer()` function of the **lme4**-package) as nicely formatted html-tables.

Before starting, sample data is loaded and sample models are fitted:

```{r, results='hide'}
# load sample data
data(efc)
# prepare grouping variables
efc$grp = as.factor(efc$e15relat)
levels(x = efc$grp) <- get_labels(efc$e15relat)
efc$care.level <- rec(efc$n4pstu, recodes = "0=0;1=1;2=2;3:4=4", val.labels = c("none", "I", "II", "III"))

# data frame for fitted model
mydf <- data.frame(
  neg_c_7 = efc$neg_c_7,
  sex = to_factor(efc$c161sex),
  c12hour = efc$c12hour,
  barthel = efc$barthtot,
  education = to_factor(efc$c172code),
  grp = efc$grp,
  carelevel = to_factor(efc$care.level)
  )

# fit sample models
fit1 <- lmer(neg_c_7 ~ sex + c12hour + barthel + (1 | grp), data = mydf)
fit2 <- lmer(neg_c_7 ~ sex + c12hour + education + barthel + (1 | grp), data = mydf)
fit3 <- lmer(neg_c_7 ~ sex + c12hour + education + barthel +
              (1 | grp) + (1 | carelevel), data = mydf)
``` 

The simplest way of producing the table output is by passing the fitted models as parameter. By default, estimates (_B_), confidence intervals (_CI_) and p-values (_p_) are reported. The models are named _Model 1_ and _Model 2_.

The resulting table is divided into three parts:

1. _Fixed parts_ - the model's fixed effects coefficients, including confidence intervals and p-values.
2. _Random parts_ - the model's group count (amount of random intercepts) as well as the Intra-Class-Correlation-Coefficient _ICC_ and information on the random effect variances (within-group, between-group etc.)
3. _Summary_ - Observations, AIC etc.

```{r}
sjt.lmer(fit1, fit2)
```


### Custom labels
You can specify the 'model' label via `depvar.labels` parameter:

```{r}
sjt.lmer(fit1, fit2,
         depvar.labels = c("Negative Impact", "Negative Impact"))
```


### More custom labels
Here is an example how to change the other labels. Note that `show.header` makes the two labels on top and top left corner appear in the table.

```{r}
sjt.lmer(fit1, fit2, show.header = TRUE, string.est = "Estimate", 
         string.ci = "Conf. Int.", string.p = "p-value",
         string.dv = "Response", string.pred = "Coefficients",
         string.interc = "Konstante",
         depvar.labels = c("Negative Impact", "Negative Impact"))
```


## Changing summary style and content

You can change the table style with specific parameters, e.g. to include CI into the same table cell as the estimates, print asterisks instead of numeric p-values etc.

```{r}
sjt.lmer(fit1, fit2,
         separate.ci.col = FALSE, # ci in same cell as estimates
         show.std = TRUE,         # also show standardized beta values
         p.numeric = FALSE,       # "*" instead of numeric values
         show.re.var = FALSE,     # no random effect variances
         show.aic = TRUE,         # AIC
         show.dev = FALSE,        # no deviance
         show.r2 = FALSE)          # no Pseudo-R2
```


## Custom variable labels

In the above example, the original variable labels are long and not much pretty. You can change variable labels either with `sjmisc::set_label()`, which will affect all future plots and tables, or pass own labels via `pred.labels`.

```{r}
sjt.lmer(fit1, fit2, pred.labels = c("Carer's Sex",
         "Hours of Care", "Elder's Dependency",
         "Mid Educational Level", "High Educational Level"))
```


## Grouping predictors

Categorical variables with more than two levels can be grouped in the table output. Grouping means, that a row with the variable label is inserted before these variables, and a value label for each category (i.e. factor level) is printed with a small margin.

```{r}
sjt.lmer(fit3, fit2, fit1, group.pred = TRUE)
```


Note that in the above example, the order of fitted model was changed. This is sometimes necessary, because grouping categorical predictors does not always work properly when multiple models with different amount and order of predictors are printed in one table.

## Models with different random intercepts

When models have different random intercepts, the `sjt.lmer()` function tries to detect these information from each model. In the _Random parts_ section of the table, information on multiple grouping levels and ICC's are printed then.

```{r}
sjt.lmer(fit1, fit2, fit3)
```


_Note that in certain cases, depending on the order of fitted models with several random intercepts, the group label might be incorrect._

## More space bewteen model columns

Especially when fitting and summarizing some more models, it might help to increase the distance between the columns that separate the models. This can be done by tweaking the `css.separatorcol` style-sheet:

```{r}
sjt.lmer(fit1, fit2, fit3, 
         CSS = list(css.separatorcol = 'padding-right:1.5em; padding-left:1.5em;'),
         show.re.var = FALSE,
         show.icc = FALSE,
         show.r2 = FALSE)
```


## Removing estimates from the output

With `remove.estmates`, specific estimates can be removed from the table output. This may make sense in case you have stepwise regression models and only want to compare the varying predictors but not the controls. `remove.estmates` either accepts the row indices of the rows of the table output that should be removed, or the coefficient's names.

When using numeric indices, the estimates' index number relates to the same order as `coef(fit)`.

### Example 1: Complete table output

Here you have the complete table output. This helps you identify the row index numbers. Especially when you have multiple models with different predictors, the estimate's position in the last model may differ from this estimate's position in the table output.

```{r}
sjt.lmer(fit1, fit2, fit3,
         show.re.var = FALSE,
         show.icc = FALSE)
```

### Example 2: Remove first coefficient (after intercept)

```{r}
sjt.lmer(fit1, fit2, fit3,
         remove.estimates = 2,
         show.re.var = FALSE,
         show.icc = FALSE)
```


### Example 3: Remove hours of care and sex

```{r}
sjt.lmer(fit1, fit2, fit3,
         remove.estimates = c("c12hour", "sex2"),
         show.re.var = FALSE,
         show.icc = FALSE)
```

